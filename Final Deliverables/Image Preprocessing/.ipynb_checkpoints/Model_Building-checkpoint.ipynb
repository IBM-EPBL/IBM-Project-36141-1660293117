{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e6e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a182c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,horizontal_flip= True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d244828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2626 images belonging to 5 classes.\n",
      "Found 1055 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'E:\\Naalaiya Thiran project\\IBM-Project-36141-1660293117\\Final Deliverables\\Data Collection\\TRAIN_SET',\n",
    "target_size=(64,64), batch_size=5, color_mode= \"rgb\", class_mode= \"sparse\"\n",
    ")\n",
    "x_test = test_datagen.flow_from_directory(\n",
    "r'E:\\Naalaiya Thiran project\\IBM-Project-36141-1660293117\\Final Deliverables\\Data Collection\\TEST_SET',\n",
    "target_size=(64, 64), batch_size=5, color_mode=\"rgb\", class_mode= \"sparse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7866520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5d2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77dd5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb0e00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 606, 1: 445, 2: 479, 3: 621, 4: 475})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(x_train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d3b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875ee6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2186e56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,733\n",
      "Trainable params: 813,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()#summary of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa965070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the cnn\n",
    "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "195afeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  5/526 [..............................] - ETA: 8s - loss: 2.1934e-07 - accuracy: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abish\\AppData\\Local\\Temp/ipykernel_31672/1560127962.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 10s 18ms/step - loss: 1.4590e-07 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.1199e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 7.8353e-08 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 6.7458e-08 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.9436e-08 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.6771e-08 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9953\n",
      "Epoch 7/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.7873e-08 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9953\n",
      "Epoch 8/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.8930e-08 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9962\n",
      "Epoch 9/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.5071e-08 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.3483e-08 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.8976e-09 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "526/526 [==============================] - 10s 19ms/step - loss: 7.6265e-09 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9953\n",
      "Epoch 13/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.6745e-09 - accuracy: 1.0000 - val_loss: 2.7674e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.1297e-09 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.9507e-09 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.8145e-09 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.4981e-09 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.7250e-09 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9953\n",
      "Epoch 19/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.2244e-09 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.6252e-10 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 0.1506 - accuracy: 0.9791 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.0086e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9896\n",
      "Epoch 23/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.4735e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 9.1168e-06 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9962\n",
      "Epoch 25/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.5783e-06 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9877\n",
      "Epoch 26/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.9171e-06 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9915\n",
      "Epoch 27/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.9105e-06 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9867\n",
      "Epoch 28/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.4153e-06 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9896\n",
      "Epoch 29/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 9.6579e-07 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9858\n",
      "Epoch 30/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 7.0317e-07 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9848\n",
      "Epoch 31/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.1438e-07 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.0897e-07 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9877\n",
      "Epoch 33/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.2390e-07 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9829\n",
      "Epoch 34/100\n",
      "526/526 [==============================] - 10s 19ms/step - loss: 2.3066e-07 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9905\n",
      "Epoch 35/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.7119e-07 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9820\n",
      "Epoch 36/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.2538e-07 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9858\n",
      "Epoch 37/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.0427e-07 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9829\n",
      "Epoch 38/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.1077e-08 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9801\n",
      "Epoch 39/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 6.1103e-08 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.1116e-08 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9820\n",
      "Epoch 41/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.7588e-08 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9829\n",
      "Epoch 42/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.4047e-08 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9791\n",
      "Epoch 43/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.5149e-08 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9801\n",
      "Epoch 44/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.9293e-08 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9782\n",
      "Epoch 45/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.7750e-08 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9801\n",
      "Epoch 46/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.4118e-08 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9754\n",
      "Epoch 47/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.1213e-08 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9801\n",
      "Epoch 48/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.6706e-09 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9791\n",
      "Epoch 49/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 6.4916e-09 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9782\n",
      "Epoch 50/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.7653e-09 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9782\n",
      "Epoch 51/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.2205e-09 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9744\n",
      "Epoch 52/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.6771e-09 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9782\n",
      "Epoch 53/100\n",
      "526/526 [==============================] - 10s 19ms/step - loss: 3.9948e-09 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9744\n",
      "Epoch 54/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.1790e-09 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9754\n",
      "Epoch 55/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.1336e-09 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.9066e-09 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9782\n",
      "Epoch 57/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.6796e-09 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9735\n",
      "Epoch 58/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 9.5331e-10 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9763\n",
      "Epoch 59/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 9.5331e-10 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9848\n",
      "Epoch 60/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.1712e-10 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9763\n",
      "Epoch 61/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.6252e-10 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9782\n",
      "Epoch 62/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.4475e-10 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9763\n",
      "Epoch 63/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.9014e-10 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9678\n",
      "Epoch 64/100\n",
      "526/526 [==============================] - 9s 18ms/step - loss: 1.8158e-10 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9706\n",
      "Epoch 65/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.1777e-10 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9706\n",
      "Epoch 66/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.4475e-10 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9687\n",
      "Epoch 67/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.7237e-10 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9678\n",
      "Epoch 68/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.5396e-11 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9592\n",
      "Epoch 69/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.8158e-10 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9687\n",
      "Epoch 70/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.8158e-10 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9592\n",
      "Epoch 71/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 0.0728 - accuracy: 0.9890 - val_loss: 0.9274 - val_accuracy: 0.8190\n",
      "Epoch 72/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.0406 - val_accuracy: 0.9915\n",
      "Epoch 73/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.5638e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9924\n",
      "Epoch 74/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.2844e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9915\n",
      "Epoch 75/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 7.1546e-05 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9915\n",
      "Epoch 76/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.7360e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9924\n",
      "Epoch 77/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.9566e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9924\n",
      "Epoch 78/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.1884e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9924\n",
      "Epoch 79/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.5826e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9924\n",
      "Epoch 80/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.1129e-05 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9943\n",
      "Epoch 81/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 7.1686e-06 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9953\n",
      "Epoch 82/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.5661e-06 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.1599e-06 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9962\n",
      "Epoch 84/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.2511e-06 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.8747e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9962\n",
      "Epoch 86/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.6088e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9972\n",
      "Epoch 87/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.0083e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 8.2898e-07 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 6.7570e-07 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
      "Epoch 90/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.7864e-07 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.1690e-07 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9981\n",
      "Epoch 92/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.7732e-07 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.4858e-07 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 94/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 9.3833e-08 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 95/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 6.3736e-08 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 5.6926e-08 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 4.8846e-08 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 3.0915e-08 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 2.9553e-08 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "526/526 [==============================] - 10s 18ms/step - loss: 1.8612e-08 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20daeff8370>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "    generator= x_train,steps_per_epoch = len(x_train),\n",
    "epochs=100, validation_data=x_test, validation_steps = len(x_test) ) # No of images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1458331",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7762dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tensorflow.keras.preprocessing.image\n",
    "\n",
    "model=load_model(\"nutrition.h5\") #loading the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27497bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =tensorflow.keras.utils.load_img(r\"C:\\Users\\abish\\Downloads\\TESTIMAGE3.jpg\",\n",
    "grayscale=False, target_size= (64,64) )  #Loading of the image\n",
    "x = tensorflow.keras.utils.img_to_array(img) #image to array\n",
    "x = np.expand_dims(x, axis = 0)#changing the shape\n",
    "predictions = np.argmax(model.predict(x),axis=1)\n",
    "#predictions = (model.predict_classes(x))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a87f6df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BANANA'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[\"APPLES\", \"BANANA\", \"ORANGE\", \"PINEAPPLE\", \"WATERMELON\"]\n",
    "result=str(index[predictions[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5f75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
