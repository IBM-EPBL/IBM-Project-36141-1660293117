{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SPRINT - 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Date\t: **02 NOVEMBER 2022**\n",
        "\n",
        "Team ID\t: **PNT2022TMID17433**\n",
        "\n",
        "Project Name :\t**AI-powered Nutrition Analyzer for Fitness Enthusiasts**\n",
        "\n",
        "Team Members : \n",
        "\n",
        "1.   Abishek M\n",
        "2.   Jaaffer Zarief A\n",
        "1.   Harish Kumar M\n",
        "1.   Mohaammed Umar Yasik R \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sLPVDKgGavvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "1kQLJD3ANOFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDmmmB4ahB1G",
        "outputId": "97190ef8-6ae4-4a89-e869-ee77cbe75af9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip '/content/drive/MyDrive/Dataset.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkXt16E7g2sQ",
        "outputId": "7db61cb7-6391-4994-e94c-d50eeca5bf6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Dataset.zip\n",
            "replace Dataset/TEST_SET/APPLES/n07740461_10011.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing"
      ],
      "metadata": {
        "id": "KgCrKFSAYO1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "OKgDI9z8Thea"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Data Augmentation"
      ],
      "metadata": {
        "id": "8qeYNoAeUPpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "9itk5t-hUCAd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Image DataGenerator Functionality To Trainset And Testset"
      ],
      "metadata": {
        "id": "a1_zKEGqm7sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory(\n",
        "    r'/content/Dataset/TRAIN_SET',\n",
        "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
        "x_test = test_datagen.flow_from_directory(\n",
        "    r'/content/Dataset/TEST_SET',\n",
        "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l0S6XKpUOUw",
        "outputId": "b80b2131-0b70-4ca1-9a83-2df800c5ecf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4118 images belonging to 5 classes.\n",
            "Found 974 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kQ05xVjqxlD",
        "outputId": "2e6e060a-8431-4a41-c0d5-fbc644fc51d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owPaMFgGrQT-",
        "outputId": "f4f4a01a-aa39-42a3-d4d9-6708ead09d8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yWWDoRDw5pIA",
        "outputId": "ace33085-b134-4522-9e18-1789b73a669e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 995, 1: 1354, 2: 1019, 3: 275, 4: 475})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from collections import Counter as c\n",
        "c(x_train .labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "aX_yNUr-Tbr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing The Model Building Libraries"
      ],
      "metadata": {
        "id": "lVZwyE5MTo5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout "
      ],
      "metadata": {
        "id": "tEtJC1nHTxCg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Initializing The Model"
      ],
      "metadata": {
        "id": "I9NGWvH7UYzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "Ds4P_-dKUumX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Adding CNN Layers"
      ],
      "metadata": {
        "id": "AtPUSEPbVGc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "classifier.add(Flatten())"
      ],
      "metadata": {
        "id": "-1OH2yZvVLQ5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Adding Dense Layers"
      ],
      "metadata": {
        "id": "qsKF5w2GWEqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax'))"
      ],
      "metadata": {
        "id": "S0k10QvlW_XO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dSfOw44XAYJ",
        "outputId": "2cd45569-975a-49b4-e1c4-3fc167c855c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,733\n",
            "Trainable params: 813,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Configure The Learning Process"
      ],
      "metadata": {
        "id": "a7-D6eqLXVvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "OaW4i5-DXbq2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train The Model"
      ],
      "metadata": {
        "id": "NNbxOTffpOT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier.fit_generator(generator=x_train,steps_per_epoch = len(x_train),epochs=20, validation_data=x_test,validation_steps = len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S_wmvKzpk1c",
        "outputId": "c7eeba7e-9d35-416b-f7f0-0d93133ecb5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "824/824 [==============================] - 23s 18ms/step - loss: 0.5912 - accuracy: 0.7763 - val_loss: 0.8622 - val_accuracy: 0.7700\n",
            "Epoch 2/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.4263 - accuracy: 0.8339 - val_loss: 0.7744 - val_accuracy: 0.7936\n",
            "Epoch 3/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.3718 - accuracy: 0.8567 - val_loss: 0.8382 - val_accuracy: 0.8090\n",
            "Epoch 4/20\n",
            "824/824 [==============================] - 15s 18ms/step - loss: 0.3523 - accuracy: 0.8674 - val_loss: 0.8890 - val_accuracy: 0.8214\n",
            "Epoch 5/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.3174 - accuracy: 0.8800 - val_loss: 1.0785 - val_accuracy: 0.8070\n",
            "Epoch 6/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.3173 - accuracy: 0.8783 - val_loss: 1.1520 - val_accuracy: 0.8039\n",
            "Epoch 7/20\n",
            "824/824 [==============================] - 16s 20ms/step - loss: 0.2963 - accuracy: 0.8868 - val_loss: 1.1995 - val_accuracy: 0.8029\n",
            "Epoch 8/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.2735 - accuracy: 0.8946 - val_loss: 1.1268 - val_accuracy: 0.8224\n",
            "Epoch 9/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.2631 - accuracy: 0.9002 - val_loss: 0.9532 - val_accuracy: 0.8224\n",
            "Epoch 10/20\n",
            "824/824 [==============================] - 15s 18ms/step - loss: 0.2416 - accuracy: 0.9072 - val_loss: 1.0720 - val_accuracy: 0.8419\n",
            "Epoch 11/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.2262 - accuracy: 0.9123 - val_loss: 1.3723 - val_accuracy: 0.7936\n",
            "Epoch 12/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.2307 - accuracy: 0.9213 - val_loss: 1.0575 - val_accuracy: 0.8491\n",
            "Epoch 13/20\n",
            "824/824 [==============================] - 15s 18ms/step - loss: 0.1975 - accuracy: 0.9252 - val_loss: 0.9828 - val_accuracy: 0.8593\n",
            "Epoch 14/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.1941 - accuracy: 0.9322 - val_loss: 1.2284 - val_accuracy: 0.8193\n",
            "Epoch 15/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.1713 - accuracy: 0.9386 - val_loss: 1.1491 - val_accuracy: 0.8265\n",
            "Epoch 16/20\n",
            "824/824 [==============================] - 15s 18ms/step - loss: 0.1489 - accuracy: 0.9432 - val_loss: 1.4268 - val_accuracy: 0.8398\n",
            "Epoch 17/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.1765 - accuracy: 0.9386 - val_loss: 1.1632 - val_accuracy: 0.8522\n",
            "Epoch 18/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.1420 - accuracy: 0.9475 - val_loss: 1.1635 - val_accuracy: 0.8522\n",
            "Epoch 19/20\n",
            "824/824 [==============================] - 16s 20ms/step - loss: 0.1186 - accuracy: 0.9570 - val_loss: 1.6517 - val_accuracy: 0.8306\n",
            "Epoch 20/20\n",
            "824/824 [==============================] - 13s 16ms/step - loss: 0.1394 - accuracy: 0.9497 - val_loss: 1.4128 - val_accuracy: 0.8552\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12e4455210>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Saving The Model"
      ],
      "metadata": {
        "id": "vuF7tEabqDWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('nutrition.h5')"
      ],
      "metadata": {
        "id": "lOsJVlViqKGN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Testing The Model"
      ],
      "metadata": {
        "id": "ofuoBxVHqYkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras_preprocessing.image import load_img\n",
        "model = load_model(\"nutrition.h5\")"
      ],
      "metadata": {
        "id": "uXhCmwdJqby9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lSQ6tnsR5pIc",
        "outputId": "08d91b6c-d2e0-44f4-e689-b1a6c8dc01ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "\n",
        "\n",
        "img = load_img(r'/content/drive/MyDrive/Colab Notebooks/Test_Images/T1.jpg',grayscale=False,target_size= (64,64))\n",
        "\n",
        "x = img_to_array(img)\n",
        "\n",
        "x = np.expand_dims(x,axis = 0)\n",
        "predict_x=model.predict(x) \n",
        "classes_x=np.argmax(predict_x,axis=-1)\n",
        "classes_x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
        "result=str(index[classes_x[0]])\n",
        "result"
      ],
      "metadata": {
        "id": "7x85qEYE0sEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c4ad5e2a-b8b7-4c34-e9d9-7d03896c27de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'APPLES'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}